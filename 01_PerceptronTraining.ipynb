{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_PerceptronTraining.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jithemji/ML/blob/main/01_PerceptronTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llX9hB9bcXzj"
      },
      "source": [
        "> Code illustration during `ML.now()` 2.0 for perceptron training \n",
        "\n",
        "**Date Created**: May 23, 2021\n",
        "\n",
        "\n",
        "**Author**: [Shivani Shimpi](https://www.linkedin.com/in/shivani-shimpi-5113a8170/)\n",
        "\n",
        "**Reach out**:\n",
        "[Email](mailto:shivanishimpi9@gmail.com) | [GitHub](https://github.com/shivanishimpi) | [LinkedIn](https://www.linkedin.com/in/shivani-shimpi-5113a8170/)\n",
        "\n",
        "\n",
        "\n",
        "Feel free to check out my [website](http://shivanishimpi.github.io/) for more information about my work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVilfTHfcxgL"
      },
      "source": [
        "# Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q39vxwhuNAN6"
      },
      "source": [
        "Teach model to predict on the following equation \n",
        "\n",
        "Equation: `y = 10x`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHNYAQUqdF9T"
      },
      "source": [
        "# Data Creation\n",
        "\n",
        "\n",
        "Since the equation we want to teach our model is `y = 10x`, we need the following dataset\n",
        "\n",
        "```\n",
        "x = [0, 1, 2, 3, 4, 5,..]\n",
        "\n",
        "y = [0, 10, 20, 30, 40, 50,..]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhCZGsvueXkI",
        "outputId": "17c798a1-7ccb-4ea8-8f79-8bb3dc6ee127"
      },
      "source": [
        "x = [i for i in range(20+1)] #list comprehension\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ut91uK_d7tA",
        "outputId": "66130bc7-f9f5-4791-cc0a-538f2b39b138"
      },
      "source": [
        "y = [i for i in range(10*20+1) if i%10==0]\n",
        "print(y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOBfE4rOgT_d"
      },
      "source": [
        "# Approach 1\n",
        "\n",
        "*Non ML Approach*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh1HeRj4OF_k"
      },
      "source": [
        "Defining a function for the equation `y = 10x`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmEJfDVRga4b",
        "outputId": "e79a1744-b48f-461c-b05b-85d361ec5f49"
      },
      "source": [
        "def tableofTen(x):\n",
        "  y = 10*x\n",
        "  return y\n",
        "\n",
        "\n",
        "for value in x:\n",
        "  print(tableofTen(value))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7lini7MhYaz"
      },
      "source": [
        "## Approach 2\n",
        "\n",
        "*ML Approach*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptrG_u4COC-t"
      },
      "source": [
        "\n",
        "We got really excited to try ML out during the course so we ended up training a neuron on the table of 10, probably something that no one would ever use again, lol\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwEnPsHdOK68"
      },
      "source": [
        "But wait!\n",
        "Before that we need the data to be split into Training and Testing, right? So let's do that!\n",
        "\n",
        "\n",
        "We are going to split the data in our case the lists `x` and `y` into four parts,\n",
        "\n",
        "- `xTrain` for training data\n",
        "- `yTrain` for training labels\n",
        "- `xTest` for testing data\n",
        "- `yTest` for testing labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVLkGH0Ph9Lw",
        "outputId": "871e2c07-98c1-434d-fdfc-a1632b56b794"
      },
      "source": [
        "print(f'This is x: {x}')\n",
        "print(f'This is y: {y}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is x: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "This is y: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz6P5BB5jg6V"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qbrM_lOhARR",
        "outputId": "05def563-7e7f-41e4-9cad-3a262f252279"
      },
      "source": [
        "xTrain = x[:-5] #Training Data\n",
        "yTrain = y[:-5] #Training Labels\n",
        "\n",
        "xTest = x[-5:] #Testing Data\n",
        "yTest = y[-5:] #Testing Labels\n",
        "\n",
        "print(f'''\n",
        "Training Data:\n",
        "\n",
        "xTrain : {xTrain}\n",
        "yTrain : {yTrain}\n",
        "\n",
        "Testing Data:\n",
        "\n",
        "xTest : {xTest}\n",
        "yTest : {yTest}\n",
        "''')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Data:\n",
            "\n",
            "xTrain : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "yTrain : [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
            "\n",
            "Testing Data:\n",
            "\n",
            "xTest : [16, 17, 18, 19, 20]\n",
            "yTest : [160, 170, 180, 190, 200]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyNVPSVOn-z"
      },
      "source": [
        "Now once we have split the data for training and testing, let's start the code for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ5BsgPjkD2z"
      },
      "source": [
        "#Importing the necessary libraries/frameworks\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgWK0f1AOyQB"
      },
      "source": [
        "We are using [TensorFlow](https://www.tensorflow.org/) 2.0 and keras for building ML models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUPQHftSkj-R"
      },
      "source": [
        "#perceptron model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(units=1, input_shape=[1]) \n",
        "])\n",
        "\n",
        "#unit here denotes the number of neurons and input_shape denotes the shape of the input data that you provide your neuron here"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T57ZKOTPpAWX"
      },
      "source": [
        "Now that we have defined the model, we need to compile it to reduce the error* during the training phase.\n",
        "\n",
        "We use the `adam` optimizer, but you can feel free to use `sgd`, `rmsprop`, `adamax`, `adagrad`, or others.\n",
        "\n",
        "Since this is a regression problem (how do we know it is regression? look at the equation above `y = 10x`) we are going to use mean absolute error `mae` but you can try mean squared error `mse` as well\n",
        "\n",
        "\n",
        "*error is the difference between the predicted label (output of ML model) and the actual label (label you have)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93qXyK3TSDx_"
      },
      "source": [
        "### Mean Absolute Error\n",
        "\n",
        "$${\\displaystyle \\mathrm {MAE} ={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-x_{i}\\right|}{n}}}\n",
        "$$\n",
        "\n",
        "where,\n",
        "\n",
        "- $y_{i}$ denotes the true label (the labels you have)\n",
        "- $x_{i}$ denotes the predicted labels that the model outputs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz3eb9GXmURv"
      },
      "source": [
        "model.compile(optimizer='adam', loss='mae') #optimizers --> sgd, rmsprop, adamax, adagrad ; loss --> mse, mae (this is regression sample)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mngD5t01nDBF",
        "outputId": "61304042-fe25-447a-f9d3-df4a3c4cc740"
      },
      "source": [
        "numEpoch = 50 #training it for 5000 times\n",
        "\n",
        "model.fit(x=xTrain, y=yTrain, validation_data=(xTest, yTest), epochs=numEpoch)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 65.7068 - val_loss: 157.6772\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 65.6984 - val_loss: 157.6582\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.6900 - val_loss: 157.6393\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 65.6817 - val_loss: 157.6202\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 65.6733 - val_loss: 157.6013\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 65.6649 - val_loss: 157.5823\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 65.6565 - val_loss: 157.5633\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 65.6482 - val_loss: 157.5443\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 65.6398 - val_loss: 157.5253\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 65.6314 - val_loss: 157.5063\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.6230 - val_loss: 157.4873\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.6147 - val_loss: 157.4683\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 65.6063 - val_loss: 157.4493\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 65.5979 - val_loss: 157.4303\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 65.5896 - val_loss: 157.4113\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 65.5812 - val_loss: 157.3923\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 65.5728 - val_loss: 157.3733\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 65.5644 - val_loss: 157.3543\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 65.5561 - val_loss: 157.3353\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.5477 - val_loss: 157.3163\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 65.5393 - val_loss: 157.2973\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 65.5309 - val_loss: 157.2783\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 65.5226 - val_loss: 157.2593\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 65.5142 - val_loss: 157.2403\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.5058 - val_loss: 157.2213\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 65.4975 - val_loss: 157.2023\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 65.4891 - val_loss: 157.1833\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 65.4807 - val_loss: 157.1643\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.4723 - val_loss: 157.1453\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 65.4640 - val_loss: 157.1263\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 65.4556 - val_loss: 157.1073\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 65.4472 - val_loss: 157.0883\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 65.4388 - val_loss: 157.0693\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 65.4305 - val_loss: 157.0503\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 65.4221 - val_loss: 157.0313\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 65.4137 - val_loss: 157.0123\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 65.4053 - val_loss: 156.9933\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.3970 - val_loss: 156.9743\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.3886 - val_loss: 156.9553\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.3802 - val_loss: 156.9363\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 65.3718 - val_loss: 156.9173\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 65.3635 - val_loss: 156.8983\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.3551 - val_loss: 156.8793\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.3467 - val_loss: 156.8603\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 65.3383 - val_loss: 156.8413\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 65.3300 - val_loss: 156.8223\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 65.3216 - val_loss: 156.8033\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 65.3132 - val_loss: 156.7843\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 65.3049 - val_loss: 156.7653\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 65.2965 - val_loss: 156.7463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f101b5faad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww3nKX1DUHye"
      },
      "source": [
        "`val_loss` denotes how far could your models prediction be from the actual label.\n",
        "\n",
        "So let's say if you give the input `x = 10` to your model you are expecting the ideal output to be 100, why? Because `y = 10*x = 10*10 = 100`.\n",
        "\n",
        "Now you would get 100 if you're not using Machine Learning.\n",
        "If you use the Approach 1 (that works on Crisp / Boolean Logic) you would get an exact 100, but if you use machine learning (that uses fuzzy logic) you would get the value close to 100 but never exactly 100. \n",
        "\n",
        "In the current scenario it would be `10*x ± val_loss = 10*10 ± 107.8904`\n",
        "\n",
        "Because the validation loss is 107.8904, and our intention is to reduce the loss and bring it down as closer to zero as much as we can."
      ]
    }
  ]
}